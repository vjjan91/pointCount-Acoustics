---
editor_options: 
  chunk_output_type: console
---

## Repeatability analysis

In this script, we will plot data on abundance across visits by species (in other words, we choose the 1st, 3rd and 5th visit and compare it with the 2nd, 4th and 6th visits). We will extract the R2 values for the above comparison. We will then repeat the same for acoustic data on detection rates. Following this analysis, we will regress point count data against acoustic detection rate and extract R2 values. 

## Install necessary libraries
```{r}
library(tidyverse)
library(dplyr)
library(stringr)
library(vegan)
library(ggplot2)
library(scico)
library(data.table)
library(extrafont)
library(ggstatsplot)
library(ggside)
library(MASS)
library(scales)
library(rr2)
library(ggnewscale)
library(ggpubr)
library(gridtext)
library(broom)
library(rptR)
library(tidyr)
library(foreach)
library(doParallel)

# Source any custom/other internal functions necessary for analysis
source("code/01_internal-functions.R")
```

## Load dataframe containing point count and acoustic data
```{r}
datSubset <- read.csv("results/datSubset.csv")
```

## Estimate abundance for point count data and detections for acoustic data  

Here, we make a distinction before running correlative analyses that abundance corresponds to the total number of individuals of a species detected across visits to a site and can only be calculated for point count data. In the acoustic dataset, individuals are not seen and a measure of detections (estimated as the total number of times as species was heard across ~540 10-s clips). Here 540 clips correspond to the total amount of acoustic data - 90 min (540 10-s clips) of data = 15-min of data for every visit). Here, we also add a visit_number column to each object to ease subsampling of data.    
```{r}
# point-count data
# estimate total abundance across all species for each site
# include a vist_number column to sub sample data later on
abundance <- datSubset %>%
  filter(data_type == "point_count") %>%
  group_by(site_id, scientific_name,
           common_name, date) %>% 
  summarise(abundance_pc = sum(number)) 

# add visit number
abundance <- abundance %>%
  group_by(site_id) %>%
  distinct(date) %>%  # This keeps only unique dates per site
  arrange(site_id, date) %>%
  mutate(visit_number = row_number()) %>%
  ungroup() %>%
  # Now join this back to your original abundance data
  right_join(abundance, by = c("site_id", "date")) %>%
  mutate(data_type = "point_count")

# estimate total number of detections across the acoustic data
# note: we cannot call this abundance as it refers to the total number of vocalizations across all sites
# include a vist_number column to sub sample data later on
detections <- datSubset %>%
  filter(data_type == "acoustic_data") %>%
  group_by(site_id, scientific_name,
           common_name, date) %>% 
  summarise(detections_aru = sum(number)) 

# add visit number
detections <- detections %>%
  group_by(site_id) %>%
  distinct(date) %>%  # This keeps only unique dates per site
  arrange(site_id, date) %>%
  mutate(visit_number = row_number()) %>%
  ungroup() %>%
  # Now join this back to your original abundance data
  right_join(detections, by = c("site_id", "date"))

# estimating acoustic detection rates for each species for each site and visit
aruRate <- detections %>%
  mutate(aruRate = detections_aru/90) %>%
  mutate(data_type = "acoustic_data")

# Note that the column aruRate can vary between 0 to 1 for each species for each site (this value can vary across sites for each species, referring to how vocally active a species is)
```

## Run analysis at the level of each species (across all sites and treatments combined) for point count data  

Here we run analyses separately for point count data and acoustic data. First, we will filter data by visits (choosing the 1st, 3rd and 5th visit) to a site and calculate total abundance for each species. We will repeat the above by choosing the 2nd, 4th, and 6th visit to a site and calculate total abundance for each species. 
```{r}
# get rid of species with less than 20 total abundance
spp_subset <-  abundance %>%
  group_by(common_name) %>%
  summarise(abundance_pc = sum(abundance_pc)) %>%
  ungroup() %>%
  filter(abundance_pc >=20)

# subset data
# we have 45 species in total
data <- abundance %>%
  filter(common_name %in% spp_subset$common_name)

# let's create a dataframe to understand abundance for each species across visits
abundance_across_visits <- data %>%
  pivot_wider(names_from = "visit_number",
              values_from = "abundance_pc") %>%
  transform() %>%
  replace(is.na(.),0) %>%
    group_by(site_id, common_name,
             scientific_name) %>%
  summarise_at(.vars = vars(c("1":"6")), .funs = sum)

# bootstrapping the repeatability analysis
# here, we randomly sample and sum the abundance across any three visits and then regress one group against another
# we calculate the r-squared value for each bootstrapped iteration and then print the mean r-squared value for each species

# Create a complete grid of all combinations
all_combinations_pointCount <- expand_grid(
  site_id = unique(data$site_id),
  common_name = unique(data$common_name),
  visit_number = 1:6  # assuming 6 visits, adjust if different
)

# Join with actual data
data_complete <- all_combinations %>%
  left_join(data, by = c("site_id", "common_name", "visit_number")) %>%
  mutate(
    abundance_pc = replace(abundance_pc, is.na(abundance_pc), 0)  # replace NA with 0
  )

# Number of bootstrap iterations
bootstrap_iterations <- 1000

# Number of cores to use for parallel processing
n_cores <- parallel::detectCores() - 1

# Initialize parallel backend
cl <- makeCluster(n_cores)
registerDoParallel(cl)

# Get the unique species common names
unique_species <- unique(data_complete$common_name)

# Initialize a dataframe to store the mean R2 value for each species
r_squared_all_species <- data.frame(species = character(), mean_r_squared = numeric())

# Loop over each species
for (i in 1:length(unique_species)) {
  
  a <- unique_species[i]
  for_plot <- data_complete[data_complete$common_name == a,]
  unique_visits <- unique(for_plot$visit_number)
  
  # Continue only if there are at least 6 unique visit numbers
  if (length(unique_visits) >= 6) {
    
    # Parallel loop for bootstrap iterations
    r_squared_values <- foreach(b = 1:bootstrap_iterations, .combine = c, .packages = c('dplyr', 'tidyr')) %dopar% {
      # Randomly sample 3 visits for group A and the remaining for group B from any of the six visits
      all_visits <- sample(unique_visits, 6, replace = FALSE)
      group_A_visits <- sample(all_visits, 3, replace = FALSE)
      group_B_visits <- setdiff(all_visits, group_A_visits)
      
      # Group point count data for random visits
      abundance_groupA <- for_plot %>%
        filter(visit_number %in% group_A_visits) %>%
        group_by(site_id) %>%
        summarise(abundance_groupA = sum(abundance_pc))
      
      abundance_groupB <- for_plot %>%
        filter(visit_number %in% group_B_visits) %>%
        group_by(site_id) %>%
        summarise(abundance_groupB = sum(abundance_pc))
      
      abund_data_group <- full_join(abundance_groupA, abundance_groupB)
        
      # Linear regression model
      model <- lm(abundance_groupB ~ abundance_groupA, data = abund_data_group)
      summary(model)$r.squared
    }
    
    # Calculate mean R2 value for this species
    mean_r_squared <- mean(r_squared_values)
    r_squared_all_species <- r_squared_all_species %>%
      add_row(species = a, mean_r_squared = mean_r_squared)
    
    # Print the mean R2 value for the species
    cat("Species:", a, "- Mean R2:", mean_r_squared, "\n")
    
  } else {
    cat("Species:", a, "- Not enough unique visits, skipping bootstrap.\n")
  }
}

# Stop the parallel backend
stopCluster(cl)

# write the r-squared values to file
write.csv(r_squared_all_species, "results/mean-rSquared-abundance-abundance.csv", row.names = F)
```


## Run analysis at the level of each species (across all sites and treatments combined) for acoustic data 

Here we run analyses separately for acoustic data. First, we will filter data by visits (choosing the 1st, 3rd and 5th visit) to a site and calculate total acoustic detection rate for each species. We will repeat the above by choosing the 2nd, 4th, and 6th visit to a site and calculate total abundance for each species. 

```{r}
# subset data
# we have 45 species in total
aruData <- aruRate %>%
  filter(common_name %in% spp_subset$common_name)

# let's create a dataframe to understand abundance for each species across visits
aruRate_across_visits <- aruData %>%
  pivot_wider(names_from = "visit_number",
              values_from = "aruRate") %>%
  transform() %>%
  replace(is.na(.),0) %>%
    group_by(site_id, common_name,
             scientific_name) %>%
  summarise_at(.vars = vars(c("1":"6")), .funs = sum)

# Create a complete grid of all combinations
all_combinations_acoustic <- expand_grid(
  site_id = unique(aruData$site_id),
  common_name = unique(aruData$common_name),
  visit_number = 1:6  # assuming 6 visits, adjust if different
)

# Join with actual data
aruData_complete <- all_combinations_acoustic %>%
  left_join(aruData, by = c("site_id", "common_name", 
                            "visit_number")) %>%
  mutate(
    aruRate = replace(aruRate, is.na(aruRate), 0)  # replace NA with 0
  )

# Number of bootstrap iterations
bootstrap_iterations <- 1000

# Number of cores to use for parallel processing
n_cores <- parallel::detectCores() - 1

# Initialize parallel backend
cl <- makeCluster(n_cores)
registerDoParallel(cl)

# Get the unique species common names
unique_species <- unique(aruData_complete$common_name)

# Initialize a dataframe to store the mean R2 value for each species
r_squared_all_species <- data.frame(species = character(), mean_r_squared = numeric())

# Loop over each species
for (i in 1:length(unique_species)) {
  
  a <- unique_species[i]
  for_plot <- aruData_complete[aruData_complete$common_name == a,]
  unique_visits <- unique(for_plot$visit_number)
  
  # Continue only if there are at least 6 unique visit numbers
  if (length(unique_visits) >= 6) {
    
    # Parallel loop for bootstrap iterations
    r_squared_values <- foreach(b = 1:bootstrap_iterations, .combine = c, .packages = c('dplyr', 'tidyr')) %dopar% {
      # Randomly sample 3 visits for group A and the remaining for group B from any of the six visits
      all_visits <- sample(unique_visits, 6, replace = FALSE)
      group_A_visits <- sample(all_visits, 3, replace = FALSE)
      group_B_visits <- setdiff(all_visits, group_A_visits)
      
      # Group point count data for random visits
      aru_groupA <- for_plot %>%
        filter(visit_number %in% group_A_visits) %>%
        group_by(site_id) %>%
        summarise(aru_groupA = mean(aruRate))
      
      aru_groupB <- for_plot %>%
        filter(visit_number %in% group_B_visits) %>%
        group_by(site_id) %>%
        summarise(aru_groupB = mean(aruRate))
      
       aru_data_group <- full_join(aru_groupB, aru_groupA)
       
      # Linear regression model
      model <- lm(aru_groupB ~ aru_groupA, data = aru_data_group)
      summary(model)$r.squared
    }
    
    # Calculate mean R2 value for this species
    mean_r_squared <- mean(r_squared_values)
    r_squared_all_species <- r_squared_all_species %>%
      add_row(species = a, mean_r_squared = mean_r_squared)
    
    # Print the mean R2 value for the species
    cat("Species:", a, "- Mean R2:", mean_r_squared, "\n")
    
  } else {
    cat("Species:", a, "- Not enough unique visits, skipping bootstrap.\n")
  }
}

# Stop the parallel backend
stopCluster(cl)

# write the r-squared values to file
write.csv(r_squared_all_species, "results/mean-rSquared-adr-adr.csv", row.names = F)
```

## Repeatability analysis between abundance and acoustic detection rates

```{r}
# join both datasets
aru_pc <- full_join(abundance[,-c(2,4)], aruRate[,-c(2,4,6)])

# subset data
# we have 45 species in total
aru_pc <- aru_pc %>%
  filter(common_name %in% spp_subset$common_name)

# create a complete grid of all combinations
all_combinations_pc_aru <- expand_grid(
  site_id = unique(aru_pc$site_id),
  common_name = unique(aru_pc$common_name),
  data_type = unique(aru_pc$data_type),
  visit_number = 1:6  # assuming 6 visits, adjust if different
)

# Join with actual data
aru_pc_complete <- all_combinations_pc_aru %>%
  left_join(aru_pc, by = c("site_id", "common_name", 
                            "visit_number","data_type")) %>%
  mutate(
    aruRate = replace(aruRate, is.na(aruRate), 0),
    abundance_pc = replace(abundance_pc, is.na(abundance_pc), 0)# replace NA with 0
  )

# Number of bootstrap iterations
bootstrap_iterations <- 1000

# Number of cores to use for parallel processing
n_cores <- parallel::detectCores() - 1

# Initialize parallel backend
cl <- makeCluster(n_cores)
registerDoParallel(cl)

# Get the unique species common names
unique_species <- unique(aru_pc_complete$common_name)

# Initialize a dataframe to store the mean R2 value for each species
r_squared_all_species <- data.frame(species = character(), mean_r_squared = numeric())

# Loop over each species
for (i in 1:length(unique_species)) {
  
  a <- unique_species[i]
  for_plot <- aru_pc_complete[aru_pc_complete$common_name == a,]
  unique_visits <- unique(for_plot$visit_number)
  
  # Continue only if there are at least 6 unique visit numbers
  if (length(unique_visits) >= 6) {
    
    # Parallel loop for bootstrap iterations
    r_squared_values <- foreach(b = 1:bootstrap_iterations, .combine = c, .packages = c('dplyr', 'tidyr')) %dopar% {
      # Randomly sample 3 visits for group A and the remaining for group B from any of the six visits
      all_visits <- sample(unique_visits, 6, replace = FALSE)
      group_A_visits <- sample(all_visits, 3, replace = FALSE)
      group_B_visits <- setdiff(all_visits, group_A_visits)
      
      # Group point count data for random visits
      abundance_groupA <- for_plot %>%
        filter(data_type == "point_count") %>%
        filter(visit_number %in% group_A_visits) %>%
        group_by(site_id) %>%
        summarise(abundance_groupA = sum(abundance_pc))
      
      aru_groupB <- for_plot %>%
        filter(data_type == "acoustic_data") %>%
        filter(visit_number %in% group_B_visits) %>%
        group_by(site_id) %>%
        summarise(aru_groupB = mean(aruRate))
      
       aru_pc_data_group <- full_join(aru_groupB, abundance_groupA)
       
      # Linear regression model
      model <- lm(abundance_groupA ~ aru_groupB, 
                  data = aru_pc_data_group)
      summary(model)$r.squared
    }
    
    # Calculate mean R2 value for this species
    mean_r_squared <- mean(r_squared_values)
    r_squared_all_species <- r_squared_all_species %>%
      add_row(species = a, mean_r_squared = mean_r_squared)
    
    # Print the mean R2 value for the species
    cat("Species:", a, "- Mean R2:", mean_r_squared, "\n")
    
  } else {
    cat("Species:", a, "- Not enough unique visits, skipping bootstrap.\n")
  }
}

# Stop the parallel backend
stopCluster(cl)

# write the r-squared values to file
write.csv(r_squared_all_species, "results/mean-rSquared-abundance-adr.csv", row.names = F)


```








## Regressions between abundance and acoustic detection rates  

Since this analysis was previously done, we reload the dataframe to get r-squared values between abundance and acoustic detection rates. 
```{r}
# load regressions between aruRates and abundance
regressions <- read.csv("results/abundance-acousticDetectionRate-regressions.csv")
names(regressions)[6] <- "r_sq_abundance_aruRate"

# load regressions from repeatability analysis (pointCounts)
names(r2) <- c("r_squared_abundance_repeatability", "common_name", "analysis")

# load regressions from repeatability analysis (acousticDetectionRates)
names(r2_aru) <- c("r_squared_aruRate_repeatability","common_name","analysis")

# combine the dataframes
data_regressions <- left_join(regressions[,c(1,6)],r2[,c(1,2)]) %>%
  left_join(., r2_aru[,c(1,2)])

# saving file
write.csv(data_regressions,"results/r_squared_repeatability_regressions.csv",
          row.names = F)
```


